Brittany Ellich (00:01)
Welcome to the Overcommitted Podcast where we talk about our code commits, our personal commitments, and some stuff in between. I'm your host, Brittany Ellick, joined today by...

Erika (00:12)
Erica.

Jonathan Tamsut (00:13)
Hey, it's John.

Brittany Ellich (00:15)
We are a group of software engineers who initially met together on the same team at GitHub and found a common interest in continuous learning and building cool things. We continue to meet and share the things that we're learning and discuss our lives as developers. Whether you are pushing code or taking on new challenges, we are so happy you are listening. This week, we're going to talk about a very exciting topic, software engineering ethics and social media.

This is something that I feel like we have alluded to quite a bit in the past and something we've talked about a lot. And we will talk a little bit about what this issue actually is and what our thoughts are around tackling it. So to start with, I want to set the stage and talk to Erica and John a little bit about your first relationship with social media. I feel like we're all around the same age, like mid thirties ish millennials who, you know,

really were coming to adulthood around the same time that social media was first introduced. So I want to know sort of like what that felt like when you were, you know, experiencing it for the first time.

Jonathan Tamsut (01:23)
Well, I'm in my early 30s, thank you very much. Don't age me. But yeah, I could go ahead and answer. You know what's funny, I remember, I have two older sisters that are like eight years older than me and my sister was at, she was at college and Facebook came out and she was like using, cause like Facebook initially I think just rolled out to colleges and she was at UCSB.

and she had Facebook. so Facebook was definitely like the first social media platform I remember using. And I just remember, you know, going on it. like when you had like a high school girlfriend or boyfriend, you would make it Facebook official. You know, I remember that being a thing. And I never really like like social media and was always I feel like the.

It's always been weird to me to post things due to the impermanence of it all and it's kind of broadcasting. I feel like I was always like, this is silly, people are posting mundane aspects of their lives, ⁓ that's kind of the point. ⁓ yeah, Facebook was definitely my first social media interaction.

Erika (02:38)
Yeah. So discounting ⁓ AOL instant messenger, which is not social media, but I feel like is proximate in sort of like the poll that I had on my life as like ⁓ a young teenager. And like the obsession I remember of like wanting to go home and log on to AIM and

all the drama that happened over instant messenger. ⁓ My first social media platform was my space. And yeah, I definitely remember the like, you're like top was it top 10 friends, I think and top eight. Okay, yeah. And like, wow, over analyzing that I mean, the amount of brain space and emotional energy I spent into like thinking about

Brittany Ellich (03:20)
Top eight.

Erika (03:31)
who my top friends were and whose top friends list I was in. I will never get that life back and deeply regret all of that. All of that. So I didn't actually create my own Facebook profile. had when I was at summer camp, a summer camp friend set up my

profile for me and for a good like two years of my life it was entirely like jokes and made up like none of it was actually relevant to my life. ⁓ I think it said I was like related to Mary-Kate and Ashley Olsen or something like that some inside joke that was hilarious at the time. ⁓ Yeah so that was that was my introduction. How about you, Brittany?

Brittany Ellich (04:26)
Yeah, I started with MySpace and I remember the agony over, you know, deciding the top eight. And when you were fighting with a friend, she was like, oh, I'm going to remove you from my top eight or something. Like there was a lot of drama around it. I also, yeah, started on Facebook pretty, I think it was like late high school, early college. I remember it was in the days when you still could only have like 20 pictures on your Facebook maximum. And so like you had to really think about what you put there.

And yeah, I remember, I think the biggest thing that I remember is like, it was really exciting at the time, maybe in part because I was, you know, a teenager, but also because it was like this new way to interact with your friends. And, you know, I was graduating from high school, so it was a way that I could keep up with all these people that I probably would otherwise not have kept up with. And I, yeah, put a lot of mundane things out there about like, ⁓

what's on your mind? And it would be like, I'm thinking about this or I'm listening to this song or like whatever like nonsense that, you know, 17, 18 year old me cared about at the time, which is probably not something that needed to live on the internet for forever. But that's a separate thing here. ⁓ But I remember early on, was very, it was actually social. It was about, you know, people that you actually knew.

and connecting with them and that was like the draw to it and that was the promise of social media was like we're going to increase social connection. The reason I wanted to start with this is because I recently watched a video that said that the average person now spends only seven percent of their time on social media interacting with people that they know and

like at some point something changed where it's no longer social media and it's just media. ⁓ And that's kind of what I wanted to talk about today is like why did things move this direction and like what can we as software engineers think about and like you know contribute to this world that is really we're the ones that are building it. ⁓ How our input can maybe shape things potentially.

or not because big problems are hard. ⁓ So I want to just talk a little bit about next about like what social media algorithms are. If somebody wants to like take a stab at like defining that and you know what changed in social media that went from this social landscape to what it is today.

Jonathan Tamsut (06:46)
Mm. Mm-hmm.

I could, I assume this is gonna get cut. But maybe not. If, ⁓ if, if you're listening, ⁓ Brittany just shooed her cat out. also, what other thing is I remember poking people and I was like, love to poke people. I just thought it was so funny to poke people. I'd poke like my uncle.

Brittany Ellich (07:10)
Yes.

Jonathan Tamsut (07:19)
But yeah, can talk about, I can talk about, I mean, I think we all can talk about social media algorithms, but I can do that if you all want, feel free to elaborate. Yeah, so I mean, I think, ⁓ well, I think, know, know, Facebook is a good example. I mean, I think, I think for sort of a narrative purpose, so I think when you went on Facebook initially, you would kind of see posts that your friends would make, and maybe they were ordered by date.

And then there was the introduction of the new speed. And it used sort of, you know, more, you know, different algorithms to kind of recommend content to you. And so, you know, an algorithm is just a series of instructions and a lot of these platforms use some type of machine learning algorithms. So it's sort of an algorithm that kind of learns from data. And, you know, these algorithms all have some objective.

function that they're maximizing over. And so I think for a lot of these platforms, it's engagement, it's how much you're clicking, and it's often correlated with some type of advertising. You're on an advertiser's ad, or you're just being on the platform for as long as possible. And so these algorithms present you content in a way that maximizes that.

There's a blend of factors. They also do want to recommend relevant content to you because you're more likely to stay on the platform if you do.

Erika (08:56)
Yeah, I mean, I think the the cycle is a very familiar software cycle where ⁓ like the the sort of like output of the system is like some sort of metric that you're trying to optimize for. So like you mentioned, you know, time on platform. And so like

Jonathan Tamsut (08:56)
So.

Erika (09:25)
these social media platforms try to figure out how to optimize for that. So they tailor their algorithm ⁓ to support that. So ⁓ like one thing they've figured out is that if you're ⁓ like in a heightened emotional state, you will stay on the platform for longer. they'll

know, serve content that puts you in that emotional state, whether it's anger or usually anger, frustration, outrage, or like greed, know, these things you're like, I want more. Oh, I'm so mad. I'm going to like keep looking at all these things that, you know, make me mad. So they

they sort of use this as a proximate value for the overall platform, figuring that people who spend more time on the platform ⁓ or the more time that's spent on this platform means that it's more valuable overall, like monthly active users, active user time. ⁓ They can then use that to tell.

anyone who wants to advertise on the platform, for example, like, hey, we have, you know, this many people using it. We have, ⁓ you know, this much amount of time of people like using our platform. So like your advertising dollars are best spent here because ⁓ we're going to get eyeballs on your advertisements. You're going to get the most bang for your buck by, you know, paying us to serve ads. ⁓ So

I think, you know, I say it's familiar because I don't necessarily think this is like only social media that does this, but it's prevalent in social media, especially Facebook and Instagram ⁓ because of the size. Like it's sort of this cycle that, you know, grows as the companies grow and develop. And it's sort of like a self feeding thing. ⁓ And it affects more people, the more people that are on the platform. ⁓

So that's my take on it.

Brittany Ellich (11:50)
Yeah, I think that the key here where things changed is in the beginning, there were no advertisements on a lot of these applications and most of them started out, you know, being super venture capital funded. had all this money where

you know, getting pumped into them where they didn't have to worry about making money on what it was. And at some point something changed and they realized, ⁓ okay, we need to make money. The most likely thing is going to be advertisements. And that means that, you know, the more that somebody's here on the platform looking at these, at the platform in general, that means the more ads we can serve them and the more money that we can make. ⁓

And so trying to that they then became this machine that was trying to design itself to keep people on there as long as possible and to, you know, eat up as much attention as possible because it means more advertising and more money. The other.

part of it that I think is a little bit more unique to social media, although maybe it's not anymore, ⁓ is the amount of personal data that they can obtain about you to not only serve you ads, but to serve you the most targeted ads and the ads that you are most likely to engage with just by nature of being the data that they have about how long you spend looking at this video or how long you...

spend looking at that or like what your demographics are in terms of like where you are in the world searching and how old you are and all that stuff that's freely available to that platform makes it so that they can also serve you highly targeted ads that make them very valuable ads which I feel like is another thing that changed over time ⁓ and has made them maybe not more nefarious but more you know it is what they are.

Erika (13:38)
And on the topic of data, there's also the monetization vector of selling personal data, ⁓ like for profit in general. Like even if you're not even using it, you can sell it to someone else who might then use it to develop their platform.

Brittany Ellich (13:59)
Yeah, and the monetization of it created an entire economy. The creator economy didn't exist before social media platforms existed. And now you can like being an influencer as a job. ⁓ Like that's a, they're making way more money than we are. Like they're, mean, the few that are very, very successful, you know, like there's, that's an entire career too, where like their job is, you know, trying to develop the con.

Erika (14:11)
No.

Jonathan Tamsut (14:12)
Yeah.

You

Brittany Ellich (14:27)
Again, similar to the social media companies trying to develop the content that people are most likely to engage with.

Jonathan Tamsut (14:33)
Yeah, no, it is, I mean, it is such a, I mean, you know, it's like, this is such a trite topic, right? Yeah, this is like, I mean, it's trite in the sense of like, we're so immersed in, we're in this age of like social media influencers, people being online. I mean, you know, the other day I heard, you know, there's a website called OnlyFans where, you know, people sell adult content and there's the-

I saw an article saying that someone made like literally like 80 million dollars in a year selling pictures. And right, you know, all of these are sort of hitting our sort of dopamine reward systems and having just massive impacts on us on a societal level. you know, mean, Erica, you shared like that sort of quote right before, ⁓ you know, we met and, you know, I think like obviously incentives play a huge role here.

I think Brittany, I know you read this book, ⁓ Careless People, was this sort of high level executive at Metta kind of talking about her experience there. mean, ⁓ obviously these social media companies are incentivized to maximize shareholder profit.

humans are easy to manipulate, especially when you have a team of really intelligent people collecting, you know, this sort of surveillance capitalism regime where they're collecting information about us and then can develop these machine learning models that perfectly manipulate us. ⁓ And ⁓ I think, you know, we need, there's certainly needs, I think there needs, something needs to change. And, you know, I think there are

It's like with chat GPT, their pricing model, people pay a subscription. We need that for social media a little bit more. And I think people are becoming more cognizant of the effects of social media, especially on kids. But it's just such a wild time. And it's funny, it's like, I see...

older relatives in their 50s and 60s glitching their phone. I'm like, this is like a universal human thing. It's not just us young kids. So it's kind of crazy to think the impact that this has on our world. part of that is easily visible when you just look at the earnings of these social media companies. I look at Meta's valuation. Look at Snap. Look at all these social media companies. ⁓

Even Google, right? mean, their primary driver is advertising, know, targeted ads. You know, they're not a social media company per se, but they kind of, you know, are another company that makes money off of ads. it's, yeah, it's wild and it's hairy and, you know, there's certainly some great things about social media, but there's a lot of...

⁓ I think we all feel a level of discomfort with sort of how it's played out.

Brittany Ellich (17:39)
Yeah, I don't think that there was ever like a bunch of software engineers and product people sitting in a room saying like, how do we design this thing to, you know, make everybody in the world more like angry and more like, you know, like increase the polarization of the political system in the United States. Like, I don't think that that was ever something like somebody's intention. It was a bunch of small changes that happened over time where somebody's like, hey, why don't we

Jonathan Tamsut (17:54)
Yeah.

Brittany Ellich (18:07)
introduce something like the infinite scroll so that you never stop to stop looking at content. Or you are using all this A-B testing just to see like, if we move this menu here, does that change how long somebody spends on the platform or how often they interact with these things? It's a bunch of little tiny decisions that add up to this big.

Jonathan Tamsut (18:12)
Yeah.

Brittany Ellich (18:30)
societal decision where we can't just say like one person is responsible. It's a lot of little tiny things that have happened over time and we can see the impact for sure over like the entire entirety of society. The you negative mental health impact on children. I cannot imagine being a teenager right now. my gosh what they have to deal with. ⁓ And you know already going through all of the

Jonathan Tamsut (18:52)
Mm-hmm.

Brittany Ellich (18:59)
changes that come with being a teenager and also having to deal with these social media influences. And I was a kid, I was just magazines. You could really easily ignore magazine. Everybody was up in arms like, there's magazines, or influencing these kids. And I was like, well, if you just don't look at them, then you're good. But that's not possible, I feel like, to interact in daily life now because so much of it happens on the internet. ⁓

Erika (19:23)
Yeah,

Jonathan Tamsut (19:23)
Mm-hmm.

Erika (19:24)
I do think that there were points that could have changed the end outcome though. There's been, ⁓ I don't know if they're leaks or reports of research within, I'm pretty sure it was Metta about the effect of ⁓ the platform on mental health for teenage girls.

Jonathan Tamsut (19:29)
Mm.

Mm-hmm.

Erika (19:53)
and,

you know, yeah, multiple studies that like, surfaced these concerns that we're all raising here. And, you know, I think there was a trade off between profit and fixing parts of the platform that, you know, encouraged those bad outcomes. And then in every choice, they chose profit. So

You know, it's like, were they intending for that outcome? No, not necessarily, but when they did find out that that was happening, they did, of course,

Brittany Ellich (20:37)
That's true. Sorry, I'm not trying to give an out to them there. Yeah, especially reading Careless. What could we have done? We were just writing code. yeah, think that book Careless People is a really good example too. A really good, first of all, it's phenomenally written, but it's also just like a really good example of those different points that came up and what choices were made during those points when it came to like,

Jonathan Tamsut (20:38)
Yeah.

all just innocent here. We're all just innocent bystanders. Yeah.

Erika (20:47)
Yeah.

Jonathan Tamsut (20:58)
You

Brittany Ellich (21:06)
like this is having a negative impact that we can like measurably see should we do something and continuously choosing not to do something and to choose profit over that. ⁓ And I think.

Putting on the engineering brain here, what options are there though to like actually course correct now, given that we live in this capitalist system where you do kind of have to, mean, are, most CEOs are beholden to the shareholders. They can't make a decision that would negatively impact profitability theoretically. like, do you do now?

Jonathan Tamsut (21:48)
Well, so you've all know Noah Hariri, he's an author, ⁓ he's written some good books. I was listening to an interview and yeah, he talked about having an information diet. Same thing with just like, you can go to a grocery store and you could buy foods that ⁓ if you eat over the long term will make you sick. I think every person needs to have some type of information diet ⁓ where they are limiting themselves. ⁓

from exposure to content. There's tons of, I use tons of these apps like BlockSite, Freedom to Block websites. I'm off Facebook, I deleted my Facebook account in 2017 and I literally have, I feel like I've lost nothing and I'm just happier because I'm someone who I would go on Facebook and compare my life to others and just become depressed. And so I'm very,

I'm not on Instagram, I don't really go on social media, and that just works for me. Obviously, there's lots of, if you have a business, advertising on these sites is important, but I do think every individual person needs to have some type of thoughtful strategy to limit their exposure and mitigate the negative consequences of these platforms, and that's just part of what being a human being is. Now, that being said,

I have like a phone addiction. I have a dopamine addiction. There are platforms that I spend too much time on and it's not healthy for me and it's really difficult, right? Just like sort of, you know, and so, ⁓ but it could be worse, I guess.

Erika (23:30)
So as engineers, ⁓ one important aspect of what we do is being cognizant of the human impact that what we're building is having and pushing to not only measure things like ⁓ engagement time, but also ⁓ this idea of human-centered metrics. ⁓ how

how is this affecting the users? ⁓ And finding ways to measure that, ⁓ making sure that we bring it up as a part of these discussions of what we're building. ⁓ Yeah, when we do find things that are seemingly negatively impacting the human experience, however we're measuring these,

principles, ⁓ like pushing back and saying like, we need to roll this back, we need to make a different decision and pushing for that. Yeah, so I think that's an important concept to keep in mind. I also understand that like in some of these big corporations, you're gonna be told potentially that it's not

like that's not what we're doing and you have to do something else and like that's a really tough place to be in. yeah, I mean, then you kind of have career decisions to make. ⁓ But I think at least understanding like our agency here and sort of like adopting the mindset that we don't want to do any harm and like, you know, ⁓ but like also

knowing that there needs to be a way to quantify that and measure it. ⁓ Yeah, I think that's the best thing that we can do in our day to day.

Jonathan Tamsut (25:37)
I really like that, Erica. think that's, yeah. I think, yeah, measuring negative externalities as an engineering, I think is important and difficult. And I think that's why bad things happen is because people don't care about or even know about negative externalities.

Brittany Ellich (25:37)
Yeah.

Yeah, I think one big thing that comes to mind ⁓ that I often think of with these large problems, I actually have a background in public health. I have a master's degree in public health that I'm clearly not using, but it did come with a lot of learning about how to manage the health of the public as it comes out. ⁓ And most of the time that results, the main thing to reach for is regulation.

don't know how effective that would be in this case. I I think it would be better than doing nothing, but like watching the videos of the people in Congress, asking questions about how phones work. I don't know. We need some sort of governing body that's not just the people in Congress to make those decisions, if that were to exist.

Erika (26:49)
Yeah.

So here's, I agree. think that especially like given the precedent of legislation around social media, there's, okay, it's like the bill that was passed like back in 1996 that said, like it's been cited a bunch to like,

know, absolve social media companies of any responsibility. And it was intended to allow, you know, the development of communication technology, but now it's basically used as like a, it's not a problem. And as far as I know, there's no like current regulation really in flight. ⁓ And, you know, there's been like, it's hard.

It's hard to regulate the processes of a technology company because it gets really hairy. Where my mind goes first for effective regulation is profit caps. Because what we're saying is like, well, part of the root cause here is that we're optimizing for profitability. And if we say, actually, this is

The absolute maximum that a social media company can make as far as profits go, anything over that cap needs to be reinvested in like community projects like education, public health, you know, ⁓ I don't know the environment, like we're using gigantic data centers that are like environmentally problematic. Like if we cap that profit and reinvest it into things that are actually positive for our society.

I think that could have positive effects, not only on the investments that are made, but also in sort of cutting off this terrible cycle of maximizing profitability.

Brittany Ellich (29:01)
Interesting. Yeah, I haven't heard that theory before, but I do think like that makes a lot of sense. Are there other examples in the United States where that like exists, where most of these companies are located? Like are profit caps a thing?

Jonathan Tamsut (29:17)
I thought at one time OpenAI, because they were technically a nonprofit, they have a weird, OpenAI, I don't know if you've read about OpenAI's legal incorporation, but yeah. I don't think profit caps are a very American thing. And yeah, it is funny. There's sort of a bunch, like Congress is kind of a lot of corrupt.

that, yeah, it's like, I don't know if they're gonna, I don't know if I have a lot of faith, I don't know if anyone or the majority of America has a lot of faith in Congress. So yeah.

Erika (29:53)
Yeah, I mean the closest thing I can think of is like income taxes and I know there are like corporate taxes and there must be like corporate tax brackets. I'm not as familiar with like the tax code and all that to intelligently speak to it, but ⁓ yeah, even if it's not a thing, I think it needs to be introduced.

Brittany Ellich (30:15)
Yeah, I do feel like, I personally, it does need to be introduced. My ability to do anything with regards to legislature is basically none. ⁓ So my opinion here, I like sort of what Erica said about, you know, personal responsibility as a software engineer. As a software engineer, we have a lot of say in the things that we build. Now we might not be making.

product decisions, but like we are making many, many macro decisions every single day over time that add up to what these products eventually become. ⁓ And so the thing that I think of as like one way to handle something that is negatively impacting society like this would be some sort of like code of ethics or something like that as software engineers to say like, hey, if we notice something that is causing harm,

because of the thing that we are working on ⁓ causing undue harm that is not what it's designed to cause, I suppose, ⁓ then we should be able to speak up and have some sort of way of referring to some sort of board of licensure or something like that where we can say, hey, I'm reporting this somewhere so that...

We know that this decision is being made intentionally and not because of these byproducts of all of these different decisions. I feel like this exists in a lot of other career paths. Like the thing that I think about is like doctors. Doctors have like a code of ethics that they have to follow to say like, I'm gonna do no harm. ⁓

Jonathan Tamsut (31:43)
Yeah.

Brittany Ellich (31:57)
And I feel like the same thing should be applied to the software engineering level because we are seeing how much harm is caused by a lot of the software that is being built.

Erika (32:08)
Yeah, I think the key point that's missing there is that there's no license to practice software engineering. ⁓ Like, because when you have a, like a, you know, an ethical violation for a doctor, for example, they take away your license to practice medicine. ⁓ But unless you have that for software engineers, like, ⁓ you know, I don't know, you have to.

Jonathan Tamsut (32:17)
Hmm.

Erika (32:38)
Like, guess, I guess the process would be like, you know, you can't put anything on the open internet unless you have a software license or like you have to report on your website. Like this was created or hosted by somebody who's, you know, not a licensed software technologist or something like that. ⁓ Which, you know, it's possible. Like we do that with SSL and ⁓ stuff like that for.

protection and encryption. So it's not necessarily out of the realm of possibility, but that would have to be, there would have to be a layer there of compliance and ⁓ adoption.

Jonathan Tamsut (33:24)
Yeah, yeah, it's like, on one hand, this feels like very futile, I don't know, it's like, I don't know if like the individual, you know, can you rely on, can you just sort of rely on like the individual goodwill of software engineers or like morality of software engineers to do anything like, ideally, would, you know, ideally, there just be like a different incentive structure that like penalized people that were actually doing harm to society. Maybe that was through

fines, government fines, or regulations that if companies violated they would either, you know, there'd be some punitive damages or punitive recourse. ⁓ And I think like, but yeah, it's hard because yeah, it's like, we think that our legislature has the ability to come up with a good incentive structure? I don't know. ⁓

But I feel like that's probably the best way is to just realign the incentive. So companies are incentivized to just like, hey, if we exploit all these people and make a ton of money, because I just think that's going to keep on happening. ⁓

Brittany Ellich (34:31)
Yeah, yeah, that's true.

Erika (34:32)
Yeah, the problem with lawsuits is that they're expensive and they're, they're expensive, they're time consuming and ⁓ money can drop the law in a lot of cases. So that's why that approach has been ineffective up to this point is because these companies have so much money that they can buy their way out of these problems.

Jonathan Tamsut (34:44)
Yeah.

Yeah.

But,

Brittany Ellich (34:55)
Yeah.

Jonathan Tamsut (34:56)
Pretty crazy.

Brittany Ellich (34:58)
Yeah, solving the world's problems here. As we've also alluded to talking about thinking and systems, I mean, a lot of these are very large complex systems that I don't think there's a one size approach that would fix anything. But I feel like doing nothing is probably not the right move.

Jonathan Tamsut (35:09)
Yeah.

Yeah.

Erika (35:17)
I mean, one other somewhat dumb idea that could potentially be applied is a harm warning and also a screen time cap. So this is an idea inspired by regulation of

the tobacco industry, right? So at some point we realize the tobacco industry was harmful. We require them to put warning labels on every package. ⁓ That could be applied to social media saying like this, the content here could be inaccurate or harmful ⁓ to your health, mental health, and then somehow capping the amount of time that you spend. So like only

allowing users to actually spend.

what's considered like a healthy amount of social media time. ⁓ So like require the companies to cut off any given user. ⁓ Now, of course, you could get around that by creating multiple accounts if you're really, you know, really inspired. ⁓ But I think for the most part, if you cut people's access off at like an hour a day, something like that, like that,

could go a long way to reducing some of this, like, again, ⁓ the maximizing that we were talking about that the algorithms optimize for.

Jonathan Tamsut (36:56)
Yeah, and I think that's a really interesting idea. And I wonder if in like 15 years or something, we'll see that. I mean, obviously one difference is like, you know, the effects smoking has on you is universally bad. It's like pretty easy to measure. Social media is like a little bit more complicated. I mean, I'm sure there some people who consume a lot of social media that don't have the same sort of mental health effects as others. mean, it's a lot more varied, but yeah. ⁓

Erika (37:23)
I mean, guess the counter

argument to that is like, like the overall effects of social media have been very well researched and documented. And like the same argument could be applied for like, not everyone who smokes get cancer, but like, you know, it's pretty likely that you will have negative health impacts from smoking. Not everybody does, but most people do, you know, same like you said with Facebook. It's like, okay, like,

Jonathan Tamsut (37:37)
Yeah.

Yeah.

Erika (37:52)
I left it, I am happier now. Like, you know, even if you didn't have like a diagnosed problem with Facebook, same with me. you know, the less I engage with social media, the happier I feel. To me, that's anecdotal. I don't know if I have any hard data to back that up, but ⁓ to me, that's reason and evidence enough that it's harmful on the whole.

Jonathan Tamsut (37:55)
Mm-hmm.

Yeah.

Hmm.

Yeah.

Brittany Ellich (38:19)
I think one of the things, sort of what John is speaking to there though too, like in the world of studying public health, it's really hard to prove something without a doubt causes harm. You have to have a huge body of evidence to say, hey, this particular product causes harm. So there's a lot of things. That's why everybody always says like, everything causes cancer. It's because, well, yeah, it does. It's just really hard to equate.

you know, this thing to causing cancer. We had a huge body of evidence that smoking causes cancer and we can say like, you know, it increases the risk. And so that's why we can put those warnings on things. ⁓ But it gets more difficult with things like that, like you said, that are harder to quantify, like mental health problems. That's a very difficult thing to quantify compared to like a physical disease. And that also requires a

body of legislature that makes decisions based on science. ⁓

Jonathan Tamsut (39:19)
You

Brittany Ellich (39:20)
You know, like you have to have somebody, some adult in the room that actually says like, yes, not only is this science saying that this is a thing that's a problem, we have to believe it. ⁓ And that is also increasingly problematic ⁓ as time goes on, in part because of...

Jonathan Tamsut (39:24)
Mm-hmm.

Brittany Ellich (39:42)
the, you know, the brainwashing that can come in the echo chambers that can come from social media platforms, you know, like the entire anti-vax movement can pretty much be pinpointed back to Facebook groups, which is crazy that like, you know, that's where it proliferated and like gained traction is like in these social media environments. So it's a reinforcing problem.

Erika (40:01)
Yeah.

Unfortunately, science doesn't make money unless you can sell it.

Brittany Ellich (40:10)
That's true. That's true.

We need to make science profitable.

Erika (40:15)
Yeah.

Brittany Ellich (40:16)
⁓ But with that, this has been a really fun conversation. ⁓ I don't know that we solved the world's problems, but it was really fun talking about them with you all and just going through this. So we're gonna get into our fun segment after that heavy conversation. We're gonna talk about things we've learned recently that may or may not be fun. It's up to you, I guess, whether.

that thing is a fun thing or not. But does somebody want to go first?

Jonathan Tamsut (40:46)
There you go. I've been learning about how rockets work. Recently, I've been watching a lot of YouTube videos and I bought a textbook on rocket propulsion. ⁓ yeah, rockets are pretty cool.

Erika (41:04)
newly relevant for you.

Jonathan Tamsut (41:07)
Yes, newly relevant for me.

Brittany Ellich (41:08)
Do want to go next, Erica?

Erika (41:10)
⁓ Well, I mentioned that we went to Colorado last week and I have a two-year-old daughter and I learned ⁓ I only mostly knew the words to let it go. I now can sing it back and forth ⁓ due to all the car time where she was requesting the song to be played and replayed and I sang along every time. ⁓

Brittany Ellich (41:37)
That's amazing. I also have a two year old that is obsessed with Let It Go right now and it's one of the most adorable things I think ever. That's great.

Erika (41:41)
Yeah.

Otherwise, I guess I did learn today through this episode that there is a code of ethics and professional conduct for computing professionals. So we can add that to the show notes in case anyone else is interesting. It's a self-optin ethical code, sort of inspired by medical professionals and engineering professionals.

I did not know it existed at all before, so that was something that I learned.

Brittany Ellich (42:19)
Yeah, we can definitely share that. I'll include that in the store notes through ACM, correct? That's something, I mean, that's a thing that I've, I feel like I've mentioned before needs to exist. Apparently it does exist. So I need to sign up too and figure out, you know, what that means. I think that's great. ⁓ I learned recently how to lay bricks ⁓ in a retaining wall project that

has lasted the last month and it's looking good. I'm building stairs with these bricks too, which is something that I do not feel qualified to do. Anything that's like a physical thing, like I feel fine when I'm building software, but anything that goes into the physical realm, I don't feel like I'm qualified to do, but this is actually coming along and ⁓ it's been really fun and I'm excited to be done with it soon and like enjoy the new yard once it's all done.

⁓ And that's really been a lot of my time outside of work. I haven't, I've been like taking a break from being over committed to many different things and it's been really nice just enjoying the summer.

All right, with that, thank you so much for tuning in to Overcommitted. If you like what you hear, please do follow, subscribe, or do whatever it is you do on the podcast app of your choice. Leave a review. Those are very helpful for us to get more people to find us if that's, know, if it's something that they like. Check us out on Blue Sky and please share with your friends. And as a reminder, we still have the Looks Good to Me Book Club.

and there's still plenty of time to get involved. If you would like to do that asynchronously, check out the show notes for more info. And until next week, goodbye.

